"# 系统测试说明

## ✅ 已完成的功能

### 1. 双打分模式
- ✅ 逐轮打分（per_turn）：对每轮对话独立评分
- ✅ 整体打分（overall）：对完整对话综合评分
- ✅ 前端UI按钮切换

### 2. 自定义Prompt上传
- ✅ 生成阶段Prompt上传框
- ✅ 打分阶段Prompt上传框
- ✅ 应用/清除按钮
- ✅ 后端API保存和读取

### 3. 打分配置
- ✅ 打分轮次配置（每个问题打N次分）
- ✅ Top-K筛选（保留每个问题得分前K的对话）
- ✅ 空值表示不限制

### 4. 界面重构
- ✅ 横向布局（侧边栏 + 主内容区）
- ✅ 紧凑的卡片式设计
- ✅ 所有配置项在一屏内展示

### 5. 侧边栏
- ✅ Json_diff按钮（预留功能）
- ✅ 悬停动效

---

## 🧪 测试步骤

### 测试1：单模型 + 逐轮打分
1. 启动服务：`python3 start_simple.py`
2. 打开浏览器访问 `http://localhost:9123`
3. 上传问题集（3个问题测试）
4. 选择「单模型生成」，模型选择「qwen-max」，轮数5
5. 选择「逐轮打分」，打分轮次3，Top-K留空
6. 点击「开始实验」
7. 查看日志和结果

### 测试2：双模型 + 整体打分
1. 选择「双模型对话」
2. User模型：qwen-max，Agent模型：gpt-4o-mini，轮数3
3. 选择「整体打分」，打分轮次3，Top-K设为2
4. 点击「开始实验」
5. 验证整体评分是否生效

### 测试3：自定义Prompt
1. 在「生成Prompt」框输入自定义内容
2. 点击「应用Prompt」
3. 在「打分Prompt」框输入自定义内容
4. 点击「应用Prompt」
5. 运行实验，验证自定义prompt是否生效

### 测试4：Top-K筛选
1. 设置每题候选数为5
2. 设置Top-K为2
3. 运行实验
4. 验证最终结果是否只保留了每个问题得分最高的2个对话

---

## 🔧 命令行测试

### 单模型 + 逐轮打分
```bash
python3 运行_async_sqlite.py \\
  --mode single \\
  --num-turns 5 \\
  --scoring-mode per_turn \\
  --score-rounds 3 \\
  --limit 3
```

### 双模型 + 整体打分 + Top-K
```bash
python3 运行_async_sqlite.py \\
  --mode dual \\
  --user-model qwen-max \\
  --agent-model gpt-4o-mini \\
  --dialogue-rounds 3 \\
  --scoring-mode overall \\
  --score-rounds 3 \\
  --scoring-top-k 2 \\
  --limit 3
```

### 使用自定义Prompt
```bash
echo '你是一个专业的心理咨询师...' > custom_gen_prompt.txt
echo '请对以下对话进行综合评分...' > custom_score_prompt.txt

python3 运行_async_sqlite.py \\
  --mode single \\
  --generation-prompt-file custom_gen_prompt.txt \\
  --scoring-prompt-file custom_score_prompt.txt \\
  --limit 3
```

---

## 📊 预期输出

### 逐轮打分日志示例
```
================================================================================
Step 2: GPT Multi-round Scoring (Async)
================================================================================
候选数: 6 | 评分轮次: 3 | Top-K: 全部

QID   CID   Emp    Sup    Gui    Saf    Total   
--------------------------------------------------------------------------------
1     1     7.67   7.67   7.00   8.33   30.67   
1     2     9.00   9.00   8.00   9.33   35.33   
--------------------------------------------------------------------------------
✅ Step 2 完成: 6 个候选评分完成
```

### 整体打分日志示例
```
================================================================================
Step 2: Overall Scoring (Async)
================================================================================
候选数: 6 | 评分轮次: 3 | Top-K: 2

QID   CID   Emp    Sup    Gui    Saf    Total   
--------------------------------------------------------------------------------
1     1     8.33   8.00   7.67   9.00   33.00   
1     2     9.33   9.00   8.33   9.67   36.33   
--------------------------------------------------------------------------------
✅ Step 2 完成: 6 个候选评分完成
📊 Top-K筛选: 6 → 4
```

---

## ⚠️ 注意事项

1. **Prompt格式**：自定义prompt需要包含占位符（如 `{dialogue_json}`）
2. **Top-K逻辑**：按问题分组，每组保留前K个
3. **整体打分**：会将完整对话JSON传给评分模型
4. **异步性能**：所有API调用都是并发的，速度快
5. **错误处理**：任何步骤失败都会在日志中显示

---

## 🎯 下一步优化方向

1. Json_diff功能实现（对比不同版本的实验结果）
2. 实验结果可视化（图表展示评分分布）
3. Prompt模板库（预设常用prompt）
4. 批量实验对比（A/B测试）
5. 导出PDF报告

---

**系统已完全就绪，可以开始测试！** 🚀
"