#!/usr/bin/env python3
"""
å®éªŒä¸»è„šæœ¬ v2.0 - æ¨¡å—åŒ–ç‰ˆæœ¬
ä¸‰æ­¥å›ºå®šæµç¨‹ï¼šç”Ÿæˆ â†’ è¯„åˆ† â†’ é€‰æ‹©
"""

import argparse
import os
from pathlib import Path
import logging

# å¯¼å…¥å·¥å…·æ¨¡å—
from utils.io_handler import load_questions, save_jsonl

# å¯¼å…¥æµç¨‹æ¨¡å—
from pipeline.generation import step1_qwen_generation
from pipeline.scoring import step2_gpt_scoring
from pipeline.selection import step3_selection


def setup_logger(log_file: str = None):
    """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
    if log_file:
        Path(log_file).parent.mkdir(parents=True, exist_ok=True)
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8') if log_file else logging.NullHandler(),
            logging.StreamHandler()
        ]
    )
    
    return logging.getLogger('experiment')


def main():
    parser = argparse.ArgumentParser(description='è¿è¡Œå®éªŒ v2.0')
    parser.add_argument('--limit', type=int, default=10, help='é—®é¢˜æ•°é‡é™åˆ¶')
    parser.add_argument('--candidates', type=int, default=2, help='æ¯æ¡é—®é¢˜ç”Ÿæˆå€™é€‰æ•°')
    parser.add_argument('--score-rounds', type=int, default=3, help='æ¯ä¸ªå€™é€‰è¯„åˆ†æ¬¡æ•°')
    parser.add_argument('--version', type=str, default='v1', help='å®éªŒç‰ˆæœ¬å·')
    parser.add_argument('--top-k', type=int, default=5, help='é€‰æ‹©Top-K')
    parser.add_argument('--input', type=str, default='inputs/questions.txt', help='è¾“å…¥æ–‡ä»¶')
    parser.add_argument('--log', type=str, default=None, help='æ—¥å¿—æ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    
    # è®¾ç½®è¾“å‡ºç›®å½•
    output_dir = os.path.join('Outputs', args.version)
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    
    # è®¾ç½®æ—¥å¿—
    if args.log is None:
        args.log = os.path.join(output_dir, f'experiment_{args.version}.log')
    
    logger = setup_logger(args.log)
    
    # æ—¥å¿—å¤´
    logger.info("="*80)
    logger.info(f"ğŸ§ª å®éªŒé…ç½® [{args.version}] - v2.0 æ¨¡å—åŒ–ç‰ˆæœ¬")
    logger.info("="*80)
    logger.info(f"è¾“å…¥: {args.input} | é—®é¢˜æ•°: {args.limit}")
    logger.info(f"å€™é€‰æ•°: {args.candidates} | è¯„åˆ†è½®æ¬¡: {args.score_rounds} | Top-K: {args.top_k}")
    logger.info(f"è¾“å‡ºç›®å½•: {output_dir}")
    logger.info("="*80)
    
    # åŠ è½½æ•°æ®
    questions = load_questions(args.input, args.limit)
    logger.info(f"\nâœ… å·²åŠ è½½ {len(questions)} ä¸ªé—®é¢˜")
    
    # Step 1: Qwenç”Ÿæˆ
    candidates = step1_qwen_generation(questions, args.candidates)
    output_file = os.path.join(output_dir, f"qwen_candidates_{args.version}.jsonl")
    save_jsonl(candidates, output_file)
    logger.info(f"ğŸ’¾ å·²ä¿å­˜: {output_file}")
    
    # Step 2: GPTè¯„åˆ†
    scored_candidates = step2_gpt_scoring(candidates, args.score_rounds)
    output_file = os.path.join(output_dir, f"gpt_scores_{args.version}.jsonl")
    save_jsonl(scored_candidates, output_file)
    logger.info(f"ğŸ’¾ å·²ä¿å­˜: {output_file}")
    
    # Step 3: é€‰æ‹©Top-K
    top_results = step3_selection(scored_candidates, args.top_k)
    output_file = os.path.join(output_dir, f"top_results_{args.version}.jsonl")
    save_jsonl(top_results, output_file)
    logger.info(f"ğŸ’¾ å·²ä¿å­˜: {output_file}")
    
    # å®Œæˆ
    logger.info("\n" + "="*80)
    logger.info("ğŸ‰ å®éªŒå®Œæˆï¼")
    logger.info("="*80)
    logger.info(f"è¾“å‡ºç›®å½•: {output_dir}")
    logger.info(f"  - qwen_candidates_{args.version}.jsonl")
    logger.info(f"  - gpt_scores_{args.version}.jsonl")
    logger.info(f"  - top_results_{args.version}.jsonl")
    logger.info(f"  - experiment_{args.version}.log")
    logger.info("="*80)


if __name__ == "__main__":
    main()
